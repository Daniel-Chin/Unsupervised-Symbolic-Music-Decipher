{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "c:\\Users\\iGlop\\anaconda3\\envs\\env_neural_avh\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have CUDA.\n",
      "gpu_name = 'NVIDIA GeForce RTX 3050 Ti Laptop GPU'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from subprocess import Popen\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "import pretty_midi\n",
    "import audiocraft\n",
    "from audiocraft.models.encodec import HFEncodecCompressionModel\n",
    "\n",
    "from shared import *\n",
    "from music import PIANO_RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(DENSITY_MU, DENSITY_SIGMA) = (2.520, 0.672)\n",
    "(DURATION_MU, DURATION_SIGMA) = (-1.754, 1.077)\n",
    "(VELOCITY_MU, VELOCITY_SIGMA) = (84.174, 25.561)\n",
    "(PITCH_MU, PITCH_SIGMA) = (60.229, 13.938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iGlop\\anaconda3\\envs\\env_neural_avh\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "encodec = audiocraft.models.encodec.CompressionModel.get_pretrained(\n",
    "    'facebook/encodec_32khz', DEVICE, \n",
    ")\n",
    "assert isinstance(encodec, HFEncodecCompressionModel)\n",
    "encodec.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = pretty_midi.PrettyMIDI()\n",
    "piano = pretty_midi.Instrument(0, is_drum=False, name='Piano')\n",
    "midi.instruments.append(piano)\n",
    "song_len = float(SEC_PER_DATAPOINT)\n",
    "density = torch.randn((1, )).mul(DENSITY_SIGMA).add(DENSITY_MU).exp().item()\n",
    "n_notes = round(song_len * density)\n",
    "onsets = torch.rand((n_notes, )).mul(song_len).numpy()\n",
    "durations = torch.randn((n_notes, )).mul(DURATION_SIGMA).add(DURATION_MU).exp().numpy()\n",
    "velocities = torch.randn((n_notes, )).mul(VELOCITY_SIGMA).add(VELOCITY_MU).clamp(1, 127).round().numpy()\n",
    "pitches = torch.randn((n_notes, )).mul(PITCH_SIGMA).add(PITCH_MU).round().numpy()\n",
    "pitches[np.logical_or(\n",
    "    pitches < PIANO_RANGE[0], \n",
    "    pitches > PIANO_RANGE[1], \n",
    ")] = 60\n",
    "for onset, duration, velocity, pitch in zip(\n",
    "    onsets, durations, velocities, pitches, \n",
    "):\n",
    "    piano.notes.append(pretty_midi.Note(\n",
    "        velocity=int(velocity), pitch=int(pitch), \n",
    "        start=onset, end=min(onset + duration, song_len),\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iGlop\\d\\neuralAVH\\unsupervised_symbolic_music_decipher\\data\\transformer_piano_dataset\\0.mid\n"
     ]
    }
   ],
   "source": [
    "midi_path = path.join(\n",
    "    TRANSFORMER_PIANO_DATASET_DIR, f'{i}.mid',\n",
    ")\n",
    "midi.write(midi_path)\n",
    "print(midi_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = path.join(\n",
    "    TRANSFORMER_PIANO_DATASET_DIR, 'temp.wav',\n",
    ")\n",
    "with Popen([\n",
    "    'fluidsynth', '-ni', SOUNDFONT_FILE, midi_path,\n",
    "    '-F', wav_path, '-r', str(ENCODEC_SR), \n",
    "]) as p:\n",
    "    p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 2685])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, _ = librosa.load(wav_path, sr=ENCODEC_SR, mono=True)\n",
    "wave = torch.Tensor(y).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    codes, _ = encodec.encode(wave.unsqueeze(0).unsqueeze(0))\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2684.7999999999997"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y) / ENCODEC_SR * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 166, 1931, 2019, 1770], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 166, 1931, 2019, 1770], device='cuda:0', dtype=torch.int16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.to(torch.int16)[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 15 > 2048"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neural_avh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
